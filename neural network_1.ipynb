{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testdatabase into memory, ignore duplicate rows\n",
    "# Import more data for better results\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "conn = sqlite3.connect('testdatabase.sqlite3')\n",
    "c = conn.cursor()\n",
    "c.execute('SELECT DISTINCT standard_inchi,protein_sequence,standard_value FROM small_interactions')\n",
    "d = c.fetchall()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inchi and protein sequence into ASCII, convert IC50 into binary True/False \n",
    "din=[[0] for x in range(len(d))]\n",
    "dpr=[[0] for x in range(len(d))]\n",
    "dca=[[0] for x in range(len(d))]\n",
    "i=0\n",
    "for row in d:\n",
    "    din[i] = [ord(c) for c in d[i][0]] # inchis\n",
    "    dpr[i] = [ord(c) for c in d[i][1]] # proteins\n",
    "    if d[i][2]<50:\n",
    "        dca[i] = 1\n",
    "    elif d[i][2]<100:\n",
    "        dca[i] = 2\n",
    "    elif d[i][2]<200:\n",
    "        dca[i] = 3\n",
    "    elif d[i][2]<500:\n",
    "        dca[i] = 4\n",
    "    else:\n",
    "        dca[i] = 0\n",
    "    #dca[i] = 0 if d[i][2]>200 else 1   # categories - can adjust this threshold for better results\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with zeros to max length of Inchis and Proteins\n",
    "# Since we concatenate the two later, need max length overall to pad so every conc row has same length\n",
    "maxlen=0\n",
    "for row in range(len(din)):\n",
    "    maxlen = len(din[row]) if len(din[row])>maxlen else maxlen\n",
    "    maxlen = len(dpr[row]) if len(dpr[row])>maxlen else maxlen # delete this if not conc later\n",
    "for row in range(len(din)):\n",
    "    din[row].extend([0 for x in range(maxlen-len(din[row]))])  \n",
    "    dpr[row].extend([0 for x in range(maxlen-len(dpr[row]))])  # delete this if not conc later\n",
    "#maxlen=0\n",
    "#for row in range(len(dpr)):\n",
    "#    maxlen = len(dpr[row]) if len(dpr[row])>maxlen else maxlen\n",
    "#for row in range(len(dpr)):\n",
    "#    dpr[row].extend([0 for x in range(maxlen-len(dpr[row]))])\n",
    "\n",
    "nin = np.array(din).astype(float) # turn into Numpy Array for Keras - INICHIS (samples x asciis)\n",
    "npr = np.array(dpr).astype(float) # turn into Numpy Array for Keras - PROTEINS (samples x asciis)\n",
    "nca = np.array(dca).astype(float) # turn into Numpy Array for Keras - IC50s (samples x 0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale ASCII int to float(0..1) \n",
    "maxval = 0\n",
    "for row in range(len(nin)):\n",
    "    maxval = max(nin[row]) if max(nin[row])>maxval else maxval\n",
    "for row in range(len(nin)):\n",
    "    nin[row] = np.divide(nin[row],float(maxval))\n",
    "maxval = 0\n",
    "for row in range(len(npr)):\n",
    "    maxval = max(npr[row]) if max(npr[row])>maxval else maxval\n",
    "for row in range(len(npr)):\n",
    "    npr[row] = np.divide(npr[row],float(maxval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Train and Test inputs for Keras\n",
    "# Concatenate Inchis and Proteins as a first try\n",
    "X = np.concatenate((nin,npr),axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, nca, test_size=0.2, random_state=61)\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "# one hot encode outputs - needed for Keras optimizer\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN with \n",
    "# 2x (1D Conv layer + MaxPooling)\n",
    "# 2x Dense\n",
    "# Can adjust:\n",
    "# number of Conv1D layers\n",
    "# number of Conv1D features (default=32, 16), size of Kernel (default=8,4)\n",
    "# size of MaxPooling1D (default=2,2)\n",
    "# number and size of Dense layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(48, (12), input_shape=(X_train.shape[1],1), activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=(4)))\n",
    "#model.add(Conv1D(48, (16), activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15201 samples, validate on 3801 samples\n",
      "Epoch 1/3\n",
      "15201/15201 [==============================] - 7s 459us/step - loss: 0.7522 - acc: 0.7637 - val_loss: 0.6836 - val_acc: 0.7785\n",
      "Epoch 2/3\n",
      "15201/15201 [==============================] - 5s 341us/step - loss: 0.6426 - acc: 0.7882 - val_loss: 0.6042 - val_acc: 0.7974\n",
      "Epoch 3/3\n",
      "15201/15201 [==============================] - 5s 343us/step - loss: 0.6131 - acc: 0.7946 - val_loss: 0.5902 - val_acc: 0.8008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c4bf6a0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate probabilities for all out-of-training-sample reactions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Probabilities =  [0.42  0.455 0.048 0.031 0.047]\n",
      "Actual Result =  [0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Print one prediction versus actual\n",
    "x=13  # change this\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"Prediction Probabilities = \",predictions[x])\n",
    "print(\"Actual Result = \",y_test[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category  0 : Sum(Probabilities) =  2943.8086913377047   Sum(Results) =  2905.0\n",
      "Category  1 : Sum(Probabilities) =  517.6655498892387   Sum(Results) =  497.0\n",
      "Category  2 : Sum(Probabilities) =  103.20330834126253   Sum(Results) =  103.0\n",
      "Category  3 : Sum(Probabilities) =  77.2075070230203   Sum(Results) =  113.0\n",
      "Category  4 : Sum(Probabilities) =  159.1149429625366   Sum(Results) =  183.0\n"
     ]
    }
   ],
   "source": [
    "# Analyze each result category\n",
    "for cat in range(len(predictions[0])):\n",
    "    x,y = 0.0,0.0\n",
    "    for rowp,rowr in zip(predictions,y_test):\n",
    "        x += rowp[cat]\n",
    "        y += rowr[cat]\n",
    "    print(\"Category \",cat,\": Sum(Probabilities) = \",x,\"  Sum(Results) = \",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
