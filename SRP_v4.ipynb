{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load truncated database into memory, ignore duplicate rows\n",
    "# Import more data for better results\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "conn = sqlite3.connect('trunc_database05192019.sqlite3')\n",
    "c = conn.cursor()\n",
    "c.execute('SELECT DISTINCT standard_inchi,protein_sequence,standard_value FROM interactions')\n",
    "d = c.fetchall()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inchi and protein sequence into ASCII, convert IC50 into binary True/False \n",
    "din=[[0] for x in range(len(d))]\n",
    "dpr=[[0] for x in range(len(d))]\n",
    "dca=[[0] for x in range(len(d))]\n",
    "i=0\n",
    "for row in d:\n",
    "    din[i] = [ord(c) for c in d[i][0]] # inchis\n",
    "    dpr[i] = [ord(c) for c in d[i][1]] # proteins\n",
    "    if d[i][2]=='': dca[i]=0\n",
    "    elif float(d[i][2])>100: dca[i] = 0 # categories - can adjust this threshold for better results\n",
    "    else: dca[i] = 1   \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with zeros to max length of each, Inchis and Proteins\n",
    "# Since we concatenate the two later, need max length overall to pad so every conc row has same length\n",
    "#maxlen=0\n",
    "#for row in range(len(din)):\n",
    "#    maxlen = len(din[row]) if len(din[row])>maxlen else maxlen\n",
    "#    maxlen = len(dpr[row]) if len(dpr[row])>maxlen else maxlen # delete this if not conc later\n",
    "#for row in range(len(din)):\n",
    "#    din[row].extend([0 for x in range(maxlen-len(din[row]))])  \n",
    "#    dpr[row].extend([0 for x in range(maxlen-len(dpr[row]))])  # delete this if not conc later\n",
    "maxlen=0\n",
    "for row in range(len(din)):\n",
    "    maxlen = len(din[row]) if len(din[row])>maxlen else maxlen\n",
    "for row in range(len(din)):\n",
    "    din[row].extend([0 for x in range(maxlen-len(din[row]))])\n",
    "maxlen=0\n",
    "for row in range(len(dpr)):\n",
    "    maxlen = len(dpr[row]) if len(dpr[row])>maxlen else maxlen\n",
    "for row in range(len(dpr)):\n",
    "    dpr[row].extend([0 for x in range(maxlen-len(dpr[row]))])\n",
    "\n",
    "nin = np.array(din).astype(float) # turn into Numpy Array for Keras - INICHIS (samples x asciis)\n",
    "npr = np.array(dpr).astype(float) # turn into Numpy Array for Keras - PROTEINS (samples x asciis)\n",
    "nca = np.array(dca).astype(float) # turn into Numpy Array for Keras - IC50s (samples x 0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale ASCII int to float(0..1) \n",
    "maxval = 0\n",
    "for row in range(len(nin)):\n",
    "    maxval = max(nin[row]) if max(nin[row])>maxval else maxval\n",
    "for row in range(len(nin)):\n",
    "    nin[row] = np.divide(nin[row],float(maxval))\n",
    "maxval = 0\n",
    "for row in range(len(npr)):\n",
    "    maxval = max(npr[row]) if max(npr[row])>maxval else maxval\n",
    "for row in range(len(npr)):\n",
    "    npr[row] = np.divide(npr[row],float(maxval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Train and Test inputs for Keras\n",
    "# Concatenate Inchis and Proteins as a first try\n",
    "X = np.concatenate((nin,npr),axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, nca, test_size=0.2, random_state=61)\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "# one hot encode outputs - needed for Keras optimizer\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN with \n",
    "# 2x (1D Conv layer + MaxPooling)\n",
    "# 2x Dense\n",
    "# Can adjust:\n",
    "# number of Conv1D layers\n",
    "# number of Conv1D features (default=32, 16), size of Kernel (default=8,4)\n",
    "# size of MaxPooling1D (default=2,2)\n",
    "# number and size of Dense layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(48, (12), input_shape=(X_train.shape[1],1), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(3)))\n",
    "model.add(Conv1D(24, (8), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate probabilities for all out-of-training-sample reactions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print one prediction versus actual\n",
    "x=13  # change this\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"Prediction Probabilities = \",predictions[x])\n",
    "print(\"Actual Result = \",y_test[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each result category\n",
    "for cat in range(len(predictions[0])):\n",
    "    x,y = 0.0,0.0\n",
    "    for rowp,rowr in zip(predictions,y_test):\n",
    "        x += rowp[cat]\n",
    "        y += rowr[cat]\n",
    "    print(\"Category \",cat,\": Sum(Probabilities) = \",x,\"  Sum(Results) = \",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
